{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Combine LSTM with Google trends data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m296DwCXiyut",
        "colab_type": "text"
      },
      "source": [
        "# **Combine LSTM model with Google Trends Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbwgV3ulyRnC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "ec050880-6af3-4d7e-aea1-5f7cc6c66161"
      },
      "source": [
        "!pip install pytrends"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytrends\n",
            "  Downloading https://files.pythonhosted.org/packages/74/a4/c1b1242be7d31650c6d9128a776c753db18f0e83290aaea0dd80dd31374b/pytrends-4.7.2.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytrends) (2.21.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pytrends) (0.25.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from pytrends) (4.2.6)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytrends) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytrends) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytrends) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytrends) (2019.11.28)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pytrends) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->pytrends) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas->pytrends) (1.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->pytrends) (1.12.0)\n",
            "Building wheels for collected packages: pytrends\n",
            "  Building wheel for pytrends (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytrends: filename=pytrends-4.7.2-cp36-none-any.whl size=14261 sha256=82e10f4edf21594e14160528fffe6ab5dd01acdf611c73f3f8c0f64b9a9e59ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/ae/af/51d48fbbca0563036c6f80999b7ce3f097fa591fd165047baf\n",
            "Successfully built pytrends\n",
            "Installing collected packages: pytrends\n",
            "Successfully installed pytrends-4.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mJhaVJzA0r8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "8e201855-d52f-44ae-a348-eb872d45e936"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from matplotlib import pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "min_max_scaler = MinMaxScaler()\n",
        "import joblib\n",
        "from pytrends.exceptions import ResponseError\n",
        "from pytrends.request import TrendReq\n",
        "from datetime import datetime\n",
        "from datetime import date, timedelta\n",
        "from functools import partial\n",
        "from time import sleep\n",
        "from calendar import monthrange\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36sYQUQ8i6b0",
        "colab_type": "text"
      },
      "source": [
        "**Fetch Google Searching Trends data with pytrends**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3uem8bvBnvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(list_of_files:list):\n",
        "  \"\"\"loads, downloads and perprocesses the two data sets.\n",
        "  Arguments: a list of names of the data (csv) files (the list can have length 1).\n",
        "  Returns:\n",
        "    X1 the bitcoin price as input to model() (see below).\n",
        "    X2: the additional data, pulled from the internet.\n",
        "    y: the bitcoin price as targets, i.e. the true bitcoin price (to be used for\n",
        "    training and evaluation).\n",
        "  \"\"\"\n",
        "  #Read bitcoin price file\n",
        "  df = pd.read_csv(list_of_files[0],usecols=[0,4])\n",
        "\n",
        "  if len(list_of_files)==1:\n",
        "      df['date'] =pd.to_datetime(df['date'])\n",
        "  else:\n",
        "    for i in range(1,len(list_of_files)+1):\n",
        "      df = df.append(pd.read_csv(list_of_files[i],usecols=[0,4]))\n",
        "      #sort Date\n",
        "      df['date'] =pd.to_datetime(df['date'])\n",
        "      df.sort_values(by=['date'])\n",
        "\n",
        "  #imputed missing values with pevious available value\n",
        "  df['close'].fillna(method='ffill', inplace = True)   \n",
        "  X1, y = df[:len(df)-1], df[1:len(df)]\n",
        "\n",
        "\n",
        "  #Pull data from Google Trends\n",
        "\n",
        "  # Eastern standard time UTC-05 in minutes -300\n",
        "  pytrends = TrendReq(hl='en-US', tz=-300)\n",
        "\n",
        "  kw_list = [\"bitcoin\"] # Keyword list\n",
        "  pytrends.build_payload(kw_list, cat=0, timeframe='today 5-y', geo='', gprop='')\n",
        "  df = pytrends.interest_over_time()\n",
        "\n",
        "  def get_last_date_of_month(year: int, month: int) -> date:\n",
        "      \"\"\"Given a year and a month returns an instance of the date class\n",
        "      containing the last day of the corresponding month.\n",
        "      Source: https://stackoverflow.com/questions/42950/get-last-day-of-the-month-in-python\n",
        "      \"\"\"\n",
        "      return date(year, month, monthrange(year, month)[1])\n",
        "\n",
        "\n",
        "  def convert_dates_to_timeframe(start: date, stop: date) -> str:\n",
        "      \"\"\"Given two dates, returns a stringified version of the interval between\n",
        "      the two dates which is used to retrieve data for a specific time frame\n",
        "      from Google Trends.\n",
        "      \"\"\"\n",
        "      return f\"{start.strftime('%Y-%m-%d')} {stop.strftime('%Y-%m-%d')}\"\n",
        "\n",
        "\n",
        "  def _fetch_data(pytrends, build_payload, timeframe: str) -> pd.DataFrame:\n",
        "      \"\"\"Attempts to fecth data and retries in case of a ResponseError.\"\"\"\n",
        "      attempts, fetched = 0, False\n",
        "      while not fetched:\n",
        "          try:\n",
        "              build_payload(timeframe=timeframe)\n",
        "          except ResponseError as err:\n",
        "              print(err)\n",
        "              print(f'Trying again in {60 + 5 * attempts} seconds.')\n",
        "              sleep(60 + 5 * attempts)\n",
        "              attempts += 1\n",
        "              if attempts > 3:\n",
        "                  print('Failed after 3 attemps, abort fetching.')\n",
        "                  break\n",
        "          else:\n",
        "              fetched = True\n",
        "      return pytrends.interest_over_time()\n",
        "\n",
        "\n",
        "  def get_daily_data(word: str,\n",
        "                  start_year: int,\n",
        "                  start_mon: int,\n",
        "                  stop_year: int,\n",
        "                  stop_mon: int,\n",
        "                  geo: str = 'US',\n",
        "                  verbose: bool = True,\n",
        "                  wait_time: float = 5.0) -> pd.DataFrame:\n",
        "      \"\"\"Given a word, fetches daily search volume data from Google Trends and\n",
        "      returns results in a pandas DataFrame.\n",
        "      Details: Due to the way Google Trends scales and returns data, special\n",
        "      care needs to be taken to make the daily data comparable over different\n",
        "      months. To do that, we download daily data on a month by month basis,\n",
        "      and also monthly data. The monthly data is downloaded in one go, so that\n",
        "      the monthly values are comparable amongst themselves and can be used to\n",
        "      scale the daily data. The daily data is scaled by multiplying the daily\n",
        "      value by the monthly search volume divided by 100.\n",
        "      For a more detailed explanation see http://bit.ly/trendsscaling\n",
        "      Args:\n",
        "          word (str): Word to fetch daily data for.\n",
        "          start_year (int): the start year\n",
        "          start_mon (int): start 1st day of the month\n",
        "          stop_year (int): the end year\n",
        "          stop_mon (int): end at the last day of the month\n",
        "          geo (str): geolocation\n",
        "          verbose (bool): If True, then prints the word and current time frame\n",
        "              we are fecthing the data for.\n",
        "      Returns:\n",
        "          complete (pd.DataFrame): Contains 4 columns.\n",
        "              The column named after the word argument contains the daily search\n",
        "              volume already scaled and comparable through time.\n",
        "              The column f'{word}_unscaled' is the original daily data fetched\n",
        "              month by month, and it is not comparable across different months\n",
        "              (but is comparable within a month).\n",
        "              The column f'{word}_monthly' contains the original monthly data\n",
        "              fetched at once. The values in this column have been backfilled\n",
        "              so that there are no NaN present.\n",
        "              The column 'scale' contains the scale used to obtain the scaled\n",
        "              daily data.\n",
        "      \"\"\"\n",
        "\n",
        "      # Set up start and stop dates\n",
        "      start_date = date(start_year, start_mon, 1) \n",
        "      stop_date = get_last_date_of_month(stop_year, stop_mon)\n",
        "\n",
        "      # Start pytrends for US region\n",
        "      pytrends = TrendReq(hl='en-US', tz=360)\n",
        "      # Initialize build_payload with the word we need data for\n",
        "      build_payload = partial(pytrends.build_payload,\n",
        "                              kw_list=[word], cat=0, geo=geo, gprop='')\n",
        "\n",
        "      # Obtain monthly data for all months in years [start_year, stop_year]\n",
        "      monthly = _fetch_data(pytrends, build_payload,\n",
        "                          convert_dates_to_timeframe(start_date, stop_date))\n",
        "\n",
        "      # Get daily data, month by month\n",
        "      results = {}\n",
        "      # if a timeout or too many requests error occur we need to adjust wait time\n",
        "      current = start_date\n",
        "      while current < stop_date:\n",
        "          last_date_of_month = get_last_date_of_month(current.year, current.month)\n",
        "          timeframe = convert_dates_to_timeframe(current, last_date_of_month)\n",
        "          if verbose:\n",
        "              print(f'{word}:{timeframe}')\n",
        "          results[current] = _fetch_data(pytrends, build_payload, timeframe)\n",
        "          current = last_date_of_month + timedelta(days=1)\n",
        "          sleep(wait_time)  # don't go too fast or Google will send 429s\n",
        "\n",
        "      daily = pd.concat(results.values()).drop(columns=['isPartial'])\n",
        "      complete = daily.join(monthly, lsuffix='_unscaled', rsuffix='_monthly')\n",
        "\n",
        "      # Scale daily data by monthly weights so the data is comparable\n",
        "      complete[f'{word}_monthly'].ffill(inplace=True)  # fill NaN values\n",
        "      complete['scale'] = complete[f'{word}_monthly'] / 100\n",
        "      complete[word] = complete[f'{word}_unscaled'] * complete.scale\n",
        "\n",
        "      return complete\n",
        "\n",
        "  X2 = get_daily_data('bitcoin', 2017, 1, 2020, 2, geo='US')\n",
        "  X2 = X2.drop(['bitcoin_unscaled', 'bitcoin_monthly', 'isPartial', 'scale'], axis = 1)\n",
        "  X2 = X2.reset_index()\n",
        "\n",
        "  return X1, X2, y\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tx5rY4jmjIcr",
        "colab_type": "text"
      },
      "source": [
        "**Retrieve the LSTM model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV97EB4IXBGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(filename_a1:str, X1):\n",
        "  a1_model = joblib.load(filename_a1)\n",
        "  dates = X1['date']\n",
        "  X1 = X1.drop(['date'], 1, inplace=False)\n",
        "  X1_norm = min_max_scaler.fit_transform(X1.values)\n",
        "  X1_norm = np.reshape(X1_norm, (len(X1_norm), 1, 1))\n",
        "  result = a1_model.predict(X1_norm)\n",
        "  y1 = min_max_scaler.inverse_transform(result)\n",
        "  y1_hat = pd.DataFrame(y1,columns=['y1_hat'])\n",
        "  y1_hat['date'] = dates\n",
        "  y1_hat['date'] =pd.to_datetime(y1_hat['date'])\n",
        "  return y1_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO5QBXoFfciR",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "75c1941e-ef25-45e5-a961-275bc5f019b1"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3f10ce51-dc9c-46d1-98c0-ecbd6197c531\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-3f10ce51-dc9c-46d1-98c0-ecbd6197c531\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving combined_model_Xi Kang.sav to combined_model_Xi Kang.sav\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'combined_model_Xi Kang.sav': b'\\x80\\x03csklearn.linear_model._base\\nLinearRegression\\nq\\x00)\\x81q\\x01}q\\x02(X\\r\\x00\\x00\\x00fit_interceptq\\x03\\x88X\\t\\x00\\x00\\x00normalizeq\\x04\\x89X\\x06\\x00\\x00\\x00copy_Xq\\x05\\x88X\\x06\\x00\\x00\\x00n_jobsq\\x06NX\\x05\\x00\\x00\\x00coef_q\\x07cjoblib.numpy_pickle\\nNumpyArrayWrapper\\nq\\x08)\\x81q\\t}q\\n(X\\x08\\x00\\x00\\x00subclassq\\x0bcnumpy\\nndarray\\nq\\x0cX\\x05\\x00\\x00\\x00shapeq\\rK\\x02\\x85q\\x0eX\\x05\\x00\\x00\\x00orderq\\x0fX\\x01\\x00\\x00\\x00Cq\\x10X\\x05\\x00\\x00\\x00dtypeq\\x11cnumpy\\ndtype\\nq\\x12X\\x02\\x00\\x00\\x00f8q\\x13K\\x00K\\x01\\x87q\\x14Rq\\x15(K\\x03X\\x01\\x00\\x00\\x00<q\\x16NNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\\x17bX\\n\\x00\\x00\\x00allow_mmapq\\x18\\x88ub\\xab\\xd1\\xa5Bq6\\xf6?X!\\x13.e\\x13\\xf0?X\\t\\x00\\x00\\x00_residuesq\\x19cnumpy.core.multiarray\\nscalar\\nq\\x1ah\\x15C\\x08\\xdf\\xcce4\\x86\\x1f\\xf6@q\\x1b\\x86q\\x1cRq\\x1dX\\x05\\x00\\x00\\x00rank_q\\x1eK\\x02X\\t\\x00\\x00\\x00singular_q\\x1fh\\x08)\\x81q }q!(h\\x0bh\\x0ch\\rK\\x02\\x85q\"h\\x0fh\\x10h\\x11h\\x15h\\x18\\x88ub\\xd0-s\\xf4\\xdb<\\xe8@\\x12\\xcd/\\x81\\x97\\xb4H@X\\n\\x00\\x00\\x00intercept_q#h\\x1ah\\x15C\\x08\\x00*8+^ZA\\xc0q$\\x86q%Rq&X\\x10\\x00\\x00\\x00_sklearn_versionq\\'X\\x06\\x00\\x00\\x000.22.1q(ub.'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0FqBQ0M4t6M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "21e64d50-7abc-4901-c9b1-ade9023a27e4"
      },
      "source": [
        "X1, X2, y = preprocess(['/content/BTCUSD_1d_2011-09-13_to_2019-10-23_bitstamp.csv'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bitcoin:2017-01-01 2017-01-31\n",
            "bitcoin:2017-02-01 2017-02-28\n",
            "bitcoin:2017-03-01 2017-03-31\n",
            "bitcoin:2017-04-01 2017-04-30\n",
            "bitcoin:2017-05-01 2017-05-31\n",
            "bitcoin:2017-06-01 2017-06-30\n",
            "bitcoin:2017-07-01 2017-07-31\n",
            "bitcoin:2017-08-01 2017-08-31\n",
            "bitcoin:2017-09-01 2017-09-30\n",
            "bitcoin:2017-10-01 2017-10-31\n",
            "bitcoin:2017-11-01 2017-11-30\n",
            "bitcoin:2017-12-01 2017-12-31\n",
            "bitcoin:2018-01-01 2018-01-31\n",
            "bitcoin:2018-02-01 2018-02-28\n",
            "bitcoin:2018-03-01 2018-03-31\n",
            "bitcoin:2018-04-01 2018-04-30\n",
            "bitcoin:2018-05-01 2018-05-31\n",
            "bitcoin:2018-06-01 2018-06-30\n",
            "bitcoin:2018-07-01 2018-07-31\n",
            "bitcoin:2018-08-01 2018-08-31\n",
            "bitcoin:2018-09-01 2018-09-30\n",
            "bitcoin:2018-10-01 2018-10-31\n",
            "bitcoin:2018-11-01 2018-11-30\n",
            "bitcoin:2018-12-01 2018-12-31\n",
            "bitcoin:2019-01-01 2019-01-31\n",
            "bitcoin:2019-02-01 2019-02-28\n",
            "bitcoin:2019-03-01 2019-03-31\n",
            "bitcoin:2019-04-01 2019-04-30\n",
            "bitcoin:2019-05-01 2019-05-31\n",
            "bitcoin:2019-06-01 2019-06-30\n",
            "bitcoin:2019-07-01 2019-07-31\n",
            "bitcoin:2019-08-01 2019-08-31\n",
            "bitcoin:2019-09-01 2019-09-30\n",
            "bitcoin:2019-10-01 2019-10-31\n",
            "bitcoin:2019-11-01 2019-11-30\n",
            "bitcoin:2019-12-01 2019-12-31\n",
            "bitcoin:2020-01-01 2020-01-31\n",
            "bitcoin:2020-02-01 2020-02-29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9OIWtChKkJU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "5bf104b8-9fb7-48fb-f32f-a59a16128931"
      },
      "source": [
        "y1_hat = model('model_a1_Xi Kang.sav',X1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVcZDvsWj9BE",
        "colab_type": "text"
      },
      "source": [
        "**Train the combined model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vnqs6P7h5gRr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "0c9a3513-e383-46df-f246-711fce0e7039"
      },
      "source": [
        "#merge price data with Google trends data\n",
        "merged_df = pd.merge(y1_hat, X2, on='date', how= 'inner')\n",
        "merged_df = pd.merge(merged_df, y, how='left')\n",
        "print(merged_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           y1_hat       date  bitcoin    close\n",
            "0     1000.261658 2017-01-01     2.58   997.75\n",
            "1     1015.111084 2017-01-02     4.32  1012.54\n",
            "2     1037.899780 2017-01-03     4.08  1035.24\n",
            "3     1117.898438 2017-01-04     4.86  1114.92\n",
            "4     1007.279541 2017-01-05     6.00  1004.74\n",
            "...           ...        ...      ...      ...\n",
            "1020  7959.320312 2019-10-18     2.52  7955.08\n",
            "1021  7964.690430 2019-10-19     2.34  7960.49\n",
            "1022  8237.872070 2019-10-20     3.04  8235.74\n",
            "1023  8215.957031 2019-10-21     3.36  8213.65\n",
            "1024  8029.629883 2019-10-22     3.28  8025.90\n",
            "\n",
            "[1025 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IVekrYhJK0g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "fb6cd8e5-8b93-4615-b51d-da163357aedc"
      },
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "train_size = 0.8\n",
        "regr=linear_model.LinearRegression()\n",
        "X=merged_df[['bitcoin','y1_hat']].values\n",
        "yt=merged_df['close'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, yt, test_size=train_size, random_state=0)\n",
        "\n",
        "regr.fit(X_train,y_train)\n",
        "y_pred = regr.predict(X_test)\n",
        "print('coefficients:\\n',regr.coef_)\n",
        "print('Mean squared error: %.2f'%metrics.mean_squared_error(y_test, y_pred))\n",
        "#print(regr.summary)\n",
        "comp_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
        "print(comp_df.head(25))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "coefficients:\n",
            " [1.351937   1.00473551]\n",
            "Mean squared error: 486.90\n",
            "      Actual     Predicted\n",
            "0    3998.13   4002.245392\n",
            "1     918.60    891.876552\n",
            "2    1017.97    993.562172\n",
            "3    8067.00   8083.585294\n",
            "4    7806.07   7816.301637\n",
            "5    1012.54    991.059693\n",
            "6    4099.55   4111.657795\n",
            "7    5503.36   5512.085276\n",
            "8   10850.00  10852.414790\n",
            "9    3885.87   3890.933994\n",
            "10   8946.95   8964.003281\n",
            "11   9345.11   9355.847503\n",
            "12   4822.01   4832.582708\n",
            "13  15155.62  15084.973795\n",
            "14   9648.00   9663.376774\n",
            "15   9230.00   9252.208291\n",
            "16   6437.29   6450.051029\n",
            "17   3835.79   3836.062675\n",
            "18  10808.99  10815.097819\n",
            "19   7617.98   7631.578915\n",
            "20   1039.92   1014.742537\n",
            "21   1071.02   1047.130067\n",
            "22   7396.60   7413.179002\n",
            "23   1170.34   1147.196908\n",
            "24   3576.93   3577.233553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD2bSYeEjS9Y",
        "colab_type": "text"
      },
      "source": [
        "**Forecast using combined model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euPe6id5CPIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combiner(y1_hat, X2, filename_comb):\n",
        "  merged_df = pd.merge(y1_hat, X2, on='date', how= 'inner')\n",
        "  dates = merged_df['date']\n",
        "  X_combined = merged_df[['bitcoin','y1_hat']].values\n",
        "  combined_model = joblib.load(filename_comb)\n",
        "  y_pred = combined_model.predict(X_combined)\n",
        "  y2_hat = pd.DataFrame(y_pred,columns=['y2_hat'])\n",
        "  y2_hat['date'] = dates\n",
        "  return y2_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW4et8vcOh3r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b2c4591a-0d97-4e03-e417-1095bef30e8a"
      },
      "source": [
        "y2_hat = combiner(y1_hat, X2, 'combined_model_Xi Kang.sav')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearRegression from version 0.22.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3e0Fx6C7A5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y2_hat.to_csv('y2_hat.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}